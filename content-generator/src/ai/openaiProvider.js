import OpenAI from 'openai';
import { BaseAIProvider } from './baseProvider.js';
import { logger } from '../utils/logger.js';

/**
 * OpenAI Provider для генерации контента
 */
export class OpenAIProvider extends BaseAIProvider {
    constructor(config) {
        super(config);
        
        if (!config.apiKey) {
            throw new Error('OpenAI API key is required');
        }
        
        this.client = new OpenAI({
            apiKey: config.apiKey
        });
        
        this.model = config.model || 'gpt-4o-mini';
        this.maxTokens = config.max_tokens || 4000;
        this.temperature = config.temperature || 0.7;
        this.presencePenalty = config.presence_penalty || 0.1;
        this.frequencyPenalty = config.frequency_penalty || 0.1;
        
        logger.debug(`OpenAI Provider initialized with model: ${this.model}`);
    }

    async generate(prompt, options = {}) {
        try {
            // Валидация промпта
            if (!this.validatePrompt(prompt)) {
                throw new Error('Invalid prompt provided');
            }

            logger.info(`OpenAI: Starting generation with model ${this.model}`);
            logger.debug(`Prompt length: ${prompt.length} characters`);

            const completion = await this.client.chat.completions.create({
                model: this.model,
                messages: [
                    {
                        role: 'system',
                        content: 'Ты профессиональный копирайтер, который создает качественные и интересные статьи на русском языке. Пиши естественно, информативно и увлекательно.'
                    },
                    {
                        role: 'user',
                        content: prompt
                    }
                ],
                max_tokens: options.maxTokens || this.maxTokens,
                temperature: options.temperature || this.temperature,
                presence_penalty: options.presencePenalty || this.presencePenalty,
                frequency_penalty: options.frequencyPenalty || this.frequencyPenalty,
                top_p: options.topP || 0.9
            });

            const content = completion.choices[0]?.message?.content;
            
            if (!content) {
                throw new Error('No content generated by OpenAI');
            }

            logger.success(`OpenAI: Content generated successfully (${completion.usage.total_tokens} tokens)`);

            return this.formatResponse(content, {
                model: this.model,
                tokensUsed: completion.usage.total_tokens,
                promptTokens: completion.usage.prompt_tokens,
                completionTokens: completion.usage.completion_tokens,
                finishReason: completion.choices[0].finish_reason
            });

        } catch (error) {
            logger.error('OpenAI generation failed:', error);
            return this.handleError(error);
        }
    }

    async isAvailable() {
        try {
            if (!this.hasApiKey()) {
                return false;
            }

            // Простой тест запрос для проверки доступности
            const testCompletion = await this.client.chat.completions.create({
                model: this.model,
                messages: [{ role: 'user', content: 'Test' }],
                max_tokens: 1
            });

            return Boolean(testCompletion);
        } catch (error) {
            logger.warn('OpenAI availability check failed:', error);
            return false;
        }
    }

    /**
     * Получение списка доступных моделей
     */
    async getAvailableModels() {
        try {
            const models = await this.client.models.list();
            return models.data
                .filter(model => model.id.includes('gpt'))
                .map(model => ({
                    id: model.id,
                    created: model.created,
                    ownedBy: model.owned_by
                }));
        } catch (error) {
            logger.error('Failed to get OpenAI models:', error);
            return [];
        }
    }

    /**
     * Оценка стоимости запроса
     */
    estimateCost(promptTokens, completionTokens) {
        // Примерные цены для GPT-4o-mini (на декабрь 2024)
        const pricing = {
            'gpt-4o-mini': {
                input: 0.00015,  // $ за 1K токенов
                output: 0.0006   // $ за 1K токенов
            },
            'gpt-4o': {
                input: 0.03,
                output: 0.06
            },
            'gpt-3.5-turbo': {
                input: 0.001,
                output: 0.002
            }
        };

        const modelPricing = pricing[this.model] || pricing['gpt-4o-mini'];
        
        const inputCost = (promptTokens / 1000) * modelPricing.input;
        const outputCost = (completionTokens / 1000) * modelPricing.output;
        
        return {
            inputCost,
            outputCost,
            totalCost: inputCost + outputCost,
            currency: 'USD'
        };
    }

    handleError(error) {
        const baseError = super.handleError(error);

        // Специфичные ошибки OpenAI
        if (error.code === 'invalid_api_key') {
            return {
                ...baseError,
                error: 'INVALID_API_KEY',
                message: 'Неверный OpenAI API ключ'
            };
        }

        if (error.code === 'insufficient_quota') {
            return {
                ...baseError,
                error: 'INSUFFICIENT_CREDITS',
                message: 'Недостаточно кредитов на OpenAI аккаунте'
            };
        }

        if (error.code === 'model_not_found') {
            return {
                ...baseError,
                error: 'MODEL_NOT_FOUND',
                message: `Модель ${this.model} не найдена`
            };
        }

        if (error.code === 'context_length_exceeded') {
            return {
                ...baseError,
                error: 'CONTEXT_TOO_LONG',
                message: 'Промпт слишком длинный для выбранной модели'
            };
        }

        return baseError;
    }
} 